{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":4662666,"sourceType":"datasetVersion","datasetId":2706368}],"dockerImageVersionId":31192,"isInternetEnabled":false,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# DICOM Dataset QA: Anonymization, Header Validation & Modality Tag Checks\n\nThis notebook runs basic quality checks on a DICOM dataset:\n\n1. **Anonymization checks**\n   - PHI / sensitive tags (e.g., PatientName, PatientID, InstitutionName)\n   - Private tags\n\n2. **Header validation**\n   - Mandatory DICOM tags exist and are non-empty\n   - Simple type / format checks\n\n3. **Required content**\n   - Presence of dataset-specific tags (configurable)\n\n4. **Modality-consistent tagging**\n   - Sanity checks tailored per Modality (CT, MR, etc.)\n\nThe goal is to quickly identify *bad* files: non-anonymized, missing critical meta, or inconsistent with the declared modality.\n","metadata":{}},{"cell_type":"code","source":"# ===========================\n# 0. Imports & Basic Config\n# ===========================\nimport os\nimport sys\nfrom pathlib import Path\nfrom collections import defaultdict, Counter\n\nimport pandas as pd\n\ntry:\n    import pydicom\n    from pydicom.errors import InvalidDicomError\nexcept ImportError:\n    !pip install -q pydicom\n    import pydicom\n    from pydicom.errors import InvalidDicomError\n\nDATA_ROOT = Path(\"/kaggle/input/hippocampal-sparing-dataset/HippocampalMRISlices/01\")  \n\n# If you want to limit how many files to scan during experimentation\nMAX_FILES = None  # or set like 1000","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-11T17:50:03.201344Z","iopub.execute_input":"2025-12-11T17:50:03.201660Z","iopub.status.idle":"2025-12-11T17:50:03.207928Z","shell.execute_reply.started":"2025-12-11T17:50:03.201637Z","shell.execute_reply":"2025-12-11T17:50:03.207035Z"}},"outputs":[],"execution_count":13},{"cell_type":"markdown","source":"## 1. Discover DICOM Files\n\nWe recursively walk the dataset directory and collect `.dcm` or DICOM-like files.\n\nYou can:\n- Filter by extension (`.dcm`, `.ima`, etc.), or  \n- Try *all* files and let `pydicom` decide if they’re valid DICOM.","metadata":{}},{"cell_type":"code","source":"# ===========================\n# 1. Discover DICOM Files\n# ===========================\n\ndef discover_dicom_files(root: Path, max_files=None):\n    dicom_paths = []\n    for dirpath, _, filenames in os.walk(root):\n        for fname in filenames:\n            fpath = Path(dirpath) / fname\n\n            # Option A: Extension-based\n            if fpath.suffix.lower() in {\".dcm\", \".dicom\", \".ima\", \"\"}:\n                dicom_paths.append(fpath)\n\n            # Option B: brute-force all files (comment out A, uncomment B)\n            # dicom_paths.append(fpath)\n\n            if max_files is not None and len(dicom_paths) >= max_files:\n                return dicom_paths\n    return dicom_paths\n\ndicom_files = discover_dicom_files(DATA_ROOT, max_files=MAX_FILES)\n\nprint(f\"Found {len(dicom_files)} candidate DICOM files.\")\nif len(dicom_files) == 0:\n    print(\"⚠️ No files found. Check DATA_ROOT.\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-11T17:50:03.209421Z","iopub.execute_input":"2025-12-11T17:50:03.209751Z","iopub.status.idle":"2025-12-11T17:50:03.250262Z","shell.execute_reply.started":"2025-12-11T17:50:03.209720Z","shell.execute_reply":"2025-12-11T17:50:03.249347Z"}},"outputs":[{"name":"stdout","text":"Found 277 candidate DICOM files.\n","output_type":"stream"}],"execution_count":14},{"cell_type":"markdown","source":"## 2. Safe DICOM Loader\n\nWe'll create a robust loader that:\n\n- Catches `InvalidDicomError`.\n- Uses `stop_before_pixels=True` for speed (we only care about headers).\n- Returns `None` on failure, plus a log entry for later analysis.\n","metadata":{}},{"cell_type":"code","source":"# ===========================\n# 2. Safe DICOM Loader\n# ===========================\n\ndef safe_read_dicom(path: Path):\n    try:\n        ds = pydicom.dcmread(str(path), stop_before_pixels=True, force=False)\n        return ds, None\n    except InvalidDicomError as e:\n        return None, f\"Invalid DICOM: {e}\"\n    except Exception as e:\n        return None, f\"Read error: {e}\"\n\n# Quick sanity check on first few files\nfor i, p in enumerate(dicom_files[:5]):\n    ds, err = safe_read_dicom(p)\n    print(p.name, \"OK\" if err is None else f\"ERROR: {err}\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-11T17:50:03.251101Z","iopub.execute_input":"2025-12-11T17:50:03.251346Z","iopub.status.idle":"2025-12-11T17:50:03.268164Z","shell.execute_reply.started":"2025-12-11T17:50:03.251323Z","shell.execute_reply":"2025-12-11T17:50:03.267378Z"}},"outputs":[{"name":"stdout","text":"MR.1.2.246.352.221.55685483938290936304826787115937244607.dcm OK\nMR.1.2.246.352.221.46620217304493734562111362943041802116.dcm OK\nMR.1.2.246.352.221.46610297499567687196592583109429057944.dcm OK\nMR.1.2.246.352.221.551312179015625932810521172476992959900.dcm OK\nMR.1.2.246.352.221.55732483383214337663879853476263275668.dcm OK\n","output_type":"stream"}],"execution_count":15},{"cell_type":"markdown","source":"## 3. Configuration: Anonymization & Validation Rules\n\nWe define:\n\n- **Sensitive tags**: must be empty or replaced with whitelisted dummy values.\n- **Required tags (global)**: must exist and not be blank.\n- **Modality-specific required tags**: extra requirements per modality.\n- **Allowed modalities**: to flag weird or unknown modality codes.\n\nYou can tweak these lists for your real project or regulatory profile.\n","metadata":{}},{"cell_type":"code","source":"# ===========================\n# 3. Rule Configuration\n# ===========================\n\n# DICOM keywords that often carry PHI / sensitive information\nSENSITIVE_TAGS = [\n    \"PatientName\",\n    \"PatientID\",\n    \"PatientBirthDate\",\n    \"PatientSex\",\n    \"OtherPatientIDs\",\n    \"OtherPatientNames\",\n    \"PatientAddress\",\n    \"PatientTelephoneNumbers\",\n    \"PatientMotherBirthName\",\n    \"PatientBirthName\",\n    \"ReferringPhysicianName\",\n    \"PerformingPhysicianName\",\n    \"OperatorsName\",\n    \"InstitutionName\",\n    \"InstitutionAddress\",\n    \"AccessionNumber\"\n]\n\n# Values that we consider \"safe\" for anonymized fields\n# Very opinionated – update to your anonymization policy\nANON_ALLOWED_VALUES = {\n    \"\",  # empty\n    \" \",  # whitespace\n    \"ANON\",\n    \"ANONYMOUS\",\n    \"REMOVED\",\n    \"REDACTED\",\n    \"XXXXX\",\n    \"XXXXXXXX\"\n}\n\n# Required tags for *all* images\nGLOBAL_REQUIRED_TAGS = [\n    \"StudyInstanceUID\",\n    \"SeriesInstanceUID\",\n    \"SOPInstanceUID\",\n    \"Modality\",\n    \"Rows\",\n    \"Columns\"\n]\n\n# Additional required tags per modality\nMODALITY_REQUIRED_TAGS = {\n    \"CT\": [\"KVP\"],  # typical but not universal\n    \"MR\": [\"MagneticFieldStrength\"],\n    \"CR\": [\"ViewPosition\"],\n    \"DX\": [\"ViewPosition\"],\n    \"US\": [],  # adjust as needed\n}\n\n# Allowed modality codes (to flag weird typos)\nALLOWED_MODALITIES = {\n    \"CT\", \"MR\", \"PT\", \"CR\", \"DX\", \"US\", \"XA\", \"MG\", \"RG\", \"OT\"\n}\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-11T17:50:03.269829Z","iopub.execute_input":"2025-12-11T17:50:03.270080Z","iopub.status.idle":"2025-12-11T17:50:03.277156Z","shell.execute_reply.started":"2025-12-11T17:50:03.270059Z","shell.execute_reply":"2025-12-11T17:50:03.276189Z"}},"outputs":[],"execution_count":16},{"cell_type":"markdown","source":"## 4. Helper Functions for Tag Access & Simple Checks\n\nWe’ll add utilities to:\n\n- Safely fetch tag values by keyword.\n- Determine if a value is “empty”.\n- Detect private tags.\n","metadata":{}},{"cell_type":"code","source":"# ===========================\n# 4. Helper Functions\n# ===========================\n\ndef get_tag(ds, keyword, default=None):\n    \"\"\"Safe keyword-based tag getter.\"\"\"\n    if ds is None:\n        return default\n    if keyword in ds:\n        val = ds.get(keyword)\n        # pydicom returns DataElement; .value is usually what we want\n        return getattr(val, \"value\", val)\n    # Fallback: try DataElement in dir with keyword\n    try:\n        return getattr(ds, keyword)\n    except AttributeError:\n        return default\n\n\ndef is_empty_value(v):\n    if v is None:\n        return True\n    if isinstance(v, str) and v.strip() == \"\":\n        return True\n    if isinstance(v, (list, tuple)) and len(v) == 0:\n        return True\n    return False\n\n\ndef has_private_tags(ds):\n    \"\"\"Return True if any private tag is present.\"\"\"\n    if ds is None:\n        return False\n    for elem in ds.iterall():\n        if elem.tag.is_private:\n            return True\n    return False\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-11T17:50:03.278098Z","iopub.execute_input":"2025-12-11T17:50:03.278455Z","iopub.status.idle":"2025-12-11T17:50:03.297795Z","shell.execute_reply.started":"2025-12-11T17:50:03.278426Z","shell.execute_reply":"2025-12-11T17:50:03.296588Z"}},"outputs":[],"execution_count":17},{"cell_type":"markdown","source":"## 5. Anonymization Checks\n\nWe’ll check, per file:\n\n1. Any **sensitive tag** has a value not in `ANON_ALLOWED_VALUES`.\n2. Any **private tags** exist (often contain vendor-specific or PHI).\n\nFor each file we record:\n\n- `has_phi_values` – any sensitive tag is non-empty and not anonymized.\n- `has_private_tags` – dataset still contains private elements.\n","metadata":{}},{"cell_type":"code","source":"# ===========================\n# 5. Anonymization Checks\n# ===========================\n\ndef check_anonymization(ds):\n    issues = {\n        \"has_phi_values\": False,\n        \"phi_tags\": [],\n        \"has_private_tags\": False,\n    }\n\n    # Sensitive tag content\n    for kw in SENSITIVE_TAGS:\n        val = get_tag(ds, kw)\n        if val is None:\n            continue\n        # Flatten value for simple checks\n        if isinstance(val, (list, tuple)):\n            flat_vals = [str(v).strip() for v in val if v is not None]\n            joined = \" \".join(flat_vals)\n        else:\n            joined = str(val).strip()\n\n        if joined and joined.upper() not in ANON_ALLOWED_VALUES:\n            issues[\"has_phi_values\"] = True\n            issues[\"phi_tags\"].append(kw)\n\n    # Private tags\n    if has_private_tags(ds):\n        issues[\"has_private_tags\"] = True\n\n    return issues\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-11T17:50:03.298795Z","iopub.execute_input":"2025-12-11T17:50:03.299123Z","iopub.status.idle":"2025-12-11T17:50:03.325644Z","shell.execute_reply.started":"2025-12-11T17:50:03.299096Z","shell.execute_reply":"2025-12-11T17:50:03.324725Z"}},"outputs":[],"execution_count":18},{"cell_type":"markdown","source":"## 6. Header Validation & Required Content\n\nWe validate:\n\n1. **Global required tags** (e.g., StudyInstanceUID, Modality, Rows, Columns).\n2. **Modality-specific required tags** (e.g., CT needs `KVP` in this rule set).\n3. Simple basic checks (e.g., Rows/Columns > 0, Modality in allowed set).\n\nAll of this is intentionally simple – this is a *screening* script, not a full DICOM validator.\n","metadata":{}},{"cell_type":"code","source":"# ===========================\n# 6. Header Validation\n# ===========================\n\ndef check_required_tags(ds, tags):\n    missing = []\n    empty = []\n    for kw in tags:\n        val = get_tag(ds, kw, default=None)\n        if val is None:\n            missing.append(kw)\n        elif is_empty_value(val):\n            empty.append(kw)\n    return missing, empty\n\n\ndef check_header_and_content(ds):\n    issues = {\n        \"missing_global_tags\": [],\n        \"empty_global_tags\": [],\n        \"missing_mod_tags\": [],\n        \"empty_mod_tags\": [],\n        \"invalid_rows_cols\": False,\n        \"modality_unknown\": False,\n    }\n\n    # Global required tags\n    missing, empty = check_required_tags(ds, GLOBAL_REQUIRED_TAGS)\n    issues[\"missing_global_tags\"] = missing\n    issues[\"empty_global_tags\"] = empty\n\n    modality = get_tag(ds, \"Modality\")\n    if modality is None:\n        modality = \"UNKNOWN\"\n\n    # Modality-specific tags\n    if modality in MODALITY_REQUIRED_TAGS:\n        mod_req = MODALITY_REQUIRED_TAGS[modality]\n        missing_m, empty_m = check_required_tags(ds, mod_req)\n        issues[\"missing_mod_tags\"] = missing_m\n        issues[\"empty_mod_tags\"] = empty_m\n\n    # Rows / Columns > 0\n    rows = get_tag(ds, \"Rows\")\n    cols = get_tag(ds, \"Columns\")\n    try:\n        if rows is not None and cols is not None:\n            if int(rows) <= 0 or int(cols) <= 0:\n                issues[\"invalid_rows_cols\"] = True\n    except Exception:\n        issues[\"invalid_rows_cols\"] = True\n\n    # Modality sanity\n    if modality not in ALLOWED_MODALITIES:\n        issues[\"modality_unknown\"] = True\n\n    return issues\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-11T17:50:03.337492Z","iopub.execute_input":"2025-12-11T17:50:03.337811Z","iopub.status.idle":"2025-12-11T17:50:03.351500Z","shell.execute_reply.started":"2025-12-11T17:50:03.337791Z","shell.execute_reply":"2025-12-11T17:50:03.350357Z"}},"outputs":[],"execution_count":19},{"cell_type":"markdown","source":"## 7. Modality-Consistent Tagging\n\nHere we add *lightweight* modality-specific sanity checks, e.g.:\n\n- **CT**:\n  - `KVP` present and > 0 (if required in config).\n- **MR**:\n  - `MagneticFieldStrength` is > 0.\n- **US**:\n  - `PhotometricInterpretation` is one of expected values.\n\nYou can harden or relax these rules per your clinical/research context.","metadata":{}},{"cell_type":"code","source":"# ===========================\n# 7. Modality-Consistent Checks\n# ===========================\n\ndef check_modality_consistency(ds):\n    modality = get_tag(ds, \"Modality\") or \"UNKNOWN\"\n    issues = {\n        \"modality\": modality,\n        \"ct_kvp_invalid\": False,\n        \"mr_field_invalid\": False,\n        \"us_photo_invalid\": False,\n    }\n\n    if modality == \"CT\":\n        kvp = get_tag(ds, \"KVP\")\n        try:\n            if kvp is None or float(kvp) <= 0:\n                issues[\"ct_kvp_invalid\"] = True\n        except Exception:\n            issues[\"ct_kvp_invalid\"] = True\n\n    if modality == \"MR\":\n        mfs = get_tag(ds, \"MagneticFieldStrength\")\n        try:\n            if mfs is None or float(mfs) <= 0:\n                issues[\"mr_field_invalid\"] = True\n        except Exception:\n            issues[\"mr_field_invalid\"] = True\n\n    if modality == \"US\":\n        pi = get_tag(ds, \"PhotometricInterpretation\")\n        if pi is not None:\n            pi = str(pi).upper()\n            if pi not in {\"MONOCHROME2\", \"MONOCHROME1\", \"RGB\", \"YBR_FULL\"}:\n                issues[\"us_photo_invalid\"] = True\n\n    return issues\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-11T17:50:03.353443Z","iopub.execute_input":"2025-12-11T17:50:03.353741Z","iopub.status.idle":"2025-12-11T17:50:03.379947Z","shell.execute_reply.started":"2025-12-11T17:50:03.353719Z","shell.execute_reply":"2025-12-11T17:50:03.378552Z"}},"outputs":[],"execution_count":20},{"cell_type":"markdown","source":"## 8. Run All Checks & Build a Summary Table\n\nWe iterate through all discovered DICOM files and generate a per-file report with:\n\n- File path & basic identifiers\n- Anonymization issues\n- Header issues\n- Modality consistency issues\n\nThen we aggregate counts to see how bad the dataset is.\n","metadata":{}},{"cell_type":"code","source":"# ===========================\n# 8. Run All Checks\n# ===========================\n\nrecords = []\n\nfor i, path in enumerate(dicom_files):\n    ds, err = safe_read_dicom(path)\n\n    if ds is None:\n        records.append({\n            \"file\": str(path),\n            \"read_error\": err,\n            \"modality\": None,\n            \"has_phi_values\": None,\n            \"phi_tags\": None,\n            \"has_private_tags\": None,\n            \"missing_global_tags\": None,\n            \"empty_global_tags\": None,\n            \"missing_mod_tags\": None,\n            \"empty_mod_tags\": None,\n            \"invalid_rows_cols\": None,\n            \"modality_unknown\": None,\n            \"ct_kvp_invalid\": None,\n            \"mr_field_invalid\": None,\n            \"us_photo_invalid\": None,\n        })\n        continue\n\n    modality = get_tag(ds, \"Modality\") or \"UNKNOWN\"\n    anon_issues = check_anonymization(ds)\n    header_issues = check_header_and_content(ds)\n    mod_issues = check_modality_consistency(ds)\n\n    records.append({\n        \"file\": str(path),\n        \"read_error\": None,\n        \"modality\": modality,\n        \"has_phi_values\": anon_issues[\"has_phi_values\"],\n        \"phi_tags\": \";\".join(anon_issues[\"phi_tags\"]),\n        \"has_private_tags\": anon_issues[\"has_private_tags\"],\n        \"missing_global_tags\": \";\".join(header_issues[\"missing_global_tags\"]),\n        \"empty_global_tags\": \";\".join(header_issues[\"empty_global_tags\"]),\n        \"missing_mod_tags\": \";\".join(header_issues[\"missing_mod_tags\"]),\n        \"empty_mod_tags\": \";\".join(header_issues[\"empty_mod_tags\"]),\n        \"invalid_rows_cols\": header_issues[\"invalid_rows_cols\"],\n        \"modality_unknown\": header_issues[\"modality_unknown\"],\n        \"ct_kvp_invalid\": mod_issues[\"ct_kvp_invalid\"],\n        \"mr_field_invalid\": mod_issues[\"mr_field_invalid\"],\n        \"us_photo_invalid\": mod_issues[\"us_photo_invalid\"],\n    })\n\n    if (i + 1) % 200 == 0:\n        print(f\"Processed {i+1} / {len(dicom_files)} files...\")\n\ndf = pd.DataFrame.from_records(records)\ndf.head()\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-11T17:50:03.380864Z","iopub.execute_input":"2025-12-11T17:50:03.381190Z","iopub.status.idle":"2025-12-11T17:50:04.317624Z","shell.execute_reply.started":"2025-12-11T17:50:03.381158Z","shell.execute_reply":"2025-12-11T17:50:04.316731Z"}},"outputs":[{"name":"stdout","text":"Processed 200 / 277 files...\n","output_type":"stream"},{"execution_count":21,"output_type":"execute_result","data":{"text/plain":"                                                file read_error modality  \\\n0  /kaggle/input/hippocampal-sparing-dataset/Hipp...       None       MR   \n1  /kaggle/input/hippocampal-sparing-dataset/Hipp...       None       MR   \n2  /kaggle/input/hippocampal-sparing-dataset/Hipp...       None       MR   \n3  /kaggle/input/hippocampal-sparing-dataset/Hipp...       None       MR   \n4  /kaggle/input/hippocampal-sparing-dataset/Hipp...       None       MR   \n\n   has_phi_values               phi_tags  has_private_tags  \\\n0            True  PatientName;PatientID             False   \n1            True  PatientName;PatientID             False   \n2            True  PatientName;PatientID             False   \n3            True  PatientName;PatientID             False   \n4            True  PatientName;PatientID             False   \n\n  missing_global_tags empty_global_tags       missing_mod_tags empty_mod_tags  \\\n0                                        MagneticFieldStrength                  \n1                                        MagneticFieldStrength                  \n2                                        MagneticFieldStrength                  \n3                                        MagneticFieldStrength                  \n4                                        MagneticFieldStrength                  \n\n   invalid_rows_cols  modality_unknown  ct_kvp_invalid  mr_field_invalid  \\\n0              False             False           False              True   \n1              False             False           False              True   \n2              False             False           False              True   \n3              False             False           False              True   \n4              False             False           False              True   \n\n   us_photo_invalid  \n0             False  \n1             False  \n2             False  \n3             False  \n4             False  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>file</th>\n      <th>read_error</th>\n      <th>modality</th>\n      <th>has_phi_values</th>\n      <th>phi_tags</th>\n      <th>has_private_tags</th>\n      <th>missing_global_tags</th>\n      <th>empty_global_tags</th>\n      <th>missing_mod_tags</th>\n      <th>empty_mod_tags</th>\n      <th>invalid_rows_cols</th>\n      <th>modality_unknown</th>\n      <th>ct_kvp_invalid</th>\n      <th>mr_field_invalid</th>\n      <th>us_photo_invalid</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>/kaggle/input/hippocampal-sparing-dataset/Hipp...</td>\n      <td>None</td>\n      <td>MR</td>\n      <td>True</td>\n      <td>PatientName;PatientID</td>\n      <td>False</td>\n      <td></td>\n      <td></td>\n      <td>MagneticFieldStrength</td>\n      <td></td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>True</td>\n      <td>False</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>/kaggle/input/hippocampal-sparing-dataset/Hipp...</td>\n      <td>None</td>\n      <td>MR</td>\n      <td>True</td>\n      <td>PatientName;PatientID</td>\n      <td>False</td>\n      <td></td>\n      <td></td>\n      <td>MagneticFieldStrength</td>\n      <td></td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>True</td>\n      <td>False</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>/kaggle/input/hippocampal-sparing-dataset/Hipp...</td>\n      <td>None</td>\n      <td>MR</td>\n      <td>True</td>\n      <td>PatientName;PatientID</td>\n      <td>False</td>\n      <td></td>\n      <td></td>\n      <td>MagneticFieldStrength</td>\n      <td></td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>True</td>\n      <td>False</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>/kaggle/input/hippocampal-sparing-dataset/Hipp...</td>\n      <td>None</td>\n      <td>MR</td>\n      <td>True</td>\n      <td>PatientName;PatientID</td>\n      <td>False</td>\n      <td></td>\n      <td></td>\n      <td>MagneticFieldStrength</td>\n      <td></td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>True</td>\n      <td>False</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>/kaggle/input/hippocampal-sparing-dataset/Hipp...</td>\n      <td>None</td>\n      <td>MR</td>\n      <td>True</td>\n      <td>PatientName;PatientID</td>\n      <td>False</td>\n      <td></td>\n      <td></td>\n      <td>MagneticFieldStrength</td>\n      <td></td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>True</td>\n      <td>False</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}],"execution_count":21},{"cell_type":"markdown","source":"## 9. Dataset-Level Summary\n\nWe now aggregate the results to see:\n\n- How many files fail anonymization.\n- How many files have read errors.\n- How many files miss critical tags.\n- Distribution by modality.\n","metadata":{}},{"cell_type":"code","source":"# ===========================\n# 9. Dataset-Level Summary\n# ===========================\n\nprint(\"Total files:\", len(df))\n\nprint(\"\\n--- Read Errors ---\")\nprint(df[\"read_error\"].notnull().value_counts())\n\nprint(\"\\n--- By Modality ---\")\nprint(df[\"modality\"].value_counts(dropna=False))\n\ndef count_bool(col):\n    if col not in df.columns:\n        return None\n    return df[col].fillna(False).value_counts()\n\nprint(\"\\n--- Anonymization ---\")\nprint(\"has_phi_values:\")\nprint(count_bool(\"has_phi_values\"))\nprint(\"\\nhas_private_tags:\")\nprint(count_bool(\"has_private_tags\"))\n\nprint(\"\\n--- Header Issues ---\")\nfor col in [\"invalid_rows_cols\", \"modality_unknown\"]:\n    print(f\"\\n{col}:\")\n    print(count_bool(col))\n\nprint(\"\\n--- Modality Consistency ---\")\nfor col in [\"ct_kvp_invalid\", \"mr_field_invalid\", \"us_photo_invalid\"]:\n    print(f\"\\n{col}:\")\n    print(count_bool(col))\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-11T17:50:04.318651Z","iopub.execute_input":"2025-12-11T17:50:04.319051Z","iopub.status.idle":"2025-12-11T17:50:04.336130Z","shell.execute_reply.started":"2025-12-11T17:50:04.319022Z","shell.execute_reply":"2025-12-11T17:50:04.335175Z"}},"outputs":[{"name":"stdout","text":"Total files: 277\n\n--- Read Errors ---\nread_error\nFalse    277\nName: count, dtype: int64\n\n--- By Modality ---\nmodality\nMR          276\nRTSTRUCT      1\nName: count, dtype: int64\n\n--- Anonymization ---\nhas_phi_values:\nhas_phi_values\nTrue    277\nName: count, dtype: int64\n\nhas_private_tags:\nhas_private_tags\nFalse    277\nName: count, dtype: int64\n\n--- Header Issues ---\n\ninvalid_rows_cols:\ninvalid_rows_cols\nFalse    277\nName: count, dtype: int64\n\nmodality_unknown:\nmodality_unknown\nFalse    276\nTrue       1\nName: count, dtype: int64\n\n--- Modality Consistency ---\n\nct_kvp_invalid:\nct_kvp_invalid\nFalse    277\nName: count, dtype: int64\n\nmr_field_invalid:\nmr_field_invalid\nTrue     276\nFalse      1\nName: count, dtype: int64\n\nus_photo_invalid:\nus_photo_invalid\nFalse    277\nName: count, dtype: int64\n","output_type":"stream"}],"execution_count":22},{"cell_type":"markdown","source":"## 10. Inspect Problematic Files\n\nNow we extract subsets of files with issues. From here, you can:\n\n- Download the CSV report.\n- Inspect individual headers in more detail.\n- Decide which files to drop or fix.\n","metadata":{}},{"cell_type":"code","source":"# ===========================\n# 10. Inspect Problematic Files\n# ===========================\n\nproblem_mask = (\n    df[\"read_error\"].notnull()\n    | df[\"has_phi_values\"].fillna(False)\n    | df[\"has_private_tags\"].fillna(False)\n    | df[\"invalid_rows_cols\"].fillna(False)\n    | df[\"modality_unknown\"].fillna(False)\n    | df[\"ct_kvp_invalid\"].fillna(False)\n    | df[\"mr_field_invalid\"].fillna(False)\n    | df[\"us_photo_invalid\"].fillna(False)\n)\n\ndf_problems = df[problem_mask].copy()\nprint(f\"Files with any issue: {len(df_problems)}\")\n\ndf_problems.head()\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-11T17:50:04.338047Z","iopub.execute_input":"2025-12-11T17:50:04.338529Z","iopub.status.idle":"2025-12-11T17:50:04.374438Z","shell.execute_reply.started":"2025-12-11T17:50:04.338501Z","shell.execute_reply":"2025-12-11T17:50:04.372381Z"}},"outputs":[{"name":"stdout","text":"Files with any issue: 277\n","output_type":"stream"},{"execution_count":23,"output_type":"execute_result","data":{"text/plain":"                                                file read_error modality  \\\n0  /kaggle/input/hippocampal-sparing-dataset/Hipp...       None       MR   \n1  /kaggle/input/hippocampal-sparing-dataset/Hipp...       None       MR   \n2  /kaggle/input/hippocampal-sparing-dataset/Hipp...       None       MR   \n3  /kaggle/input/hippocampal-sparing-dataset/Hipp...       None       MR   \n4  /kaggle/input/hippocampal-sparing-dataset/Hipp...       None       MR   \n\n   has_phi_values               phi_tags  has_private_tags  \\\n0            True  PatientName;PatientID             False   \n1            True  PatientName;PatientID             False   \n2            True  PatientName;PatientID             False   \n3            True  PatientName;PatientID             False   \n4            True  PatientName;PatientID             False   \n\n  missing_global_tags empty_global_tags       missing_mod_tags empty_mod_tags  \\\n0                                        MagneticFieldStrength                  \n1                                        MagneticFieldStrength                  \n2                                        MagneticFieldStrength                  \n3                                        MagneticFieldStrength                  \n4                                        MagneticFieldStrength                  \n\n   invalid_rows_cols  modality_unknown  ct_kvp_invalid  mr_field_invalid  \\\n0              False             False           False              True   \n1              False             False           False              True   \n2              False             False           False              True   \n3              False             False           False              True   \n4              False             False           False              True   \n\n   us_photo_invalid  \n0             False  \n1             False  \n2             False  \n3             False  \n4             False  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>file</th>\n      <th>read_error</th>\n      <th>modality</th>\n      <th>has_phi_values</th>\n      <th>phi_tags</th>\n      <th>has_private_tags</th>\n      <th>missing_global_tags</th>\n      <th>empty_global_tags</th>\n      <th>missing_mod_tags</th>\n      <th>empty_mod_tags</th>\n      <th>invalid_rows_cols</th>\n      <th>modality_unknown</th>\n      <th>ct_kvp_invalid</th>\n      <th>mr_field_invalid</th>\n      <th>us_photo_invalid</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>/kaggle/input/hippocampal-sparing-dataset/Hipp...</td>\n      <td>None</td>\n      <td>MR</td>\n      <td>True</td>\n      <td>PatientName;PatientID</td>\n      <td>False</td>\n      <td></td>\n      <td></td>\n      <td>MagneticFieldStrength</td>\n      <td></td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>True</td>\n      <td>False</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>/kaggle/input/hippocampal-sparing-dataset/Hipp...</td>\n      <td>None</td>\n      <td>MR</td>\n      <td>True</td>\n      <td>PatientName;PatientID</td>\n      <td>False</td>\n      <td></td>\n      <td></td>\n      <td>MagneticFieldStrength</td>\n      <td></td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>True</td>\n      <td>False</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>/kaggle/input/hippocampal-sparing-dataset/Hipp...</td>\n      <td>None</td>\n      <td>MR</td>\n      <td>True</td>\n      <td>PatientName;PatientID</td>\n      <td>False</td>\n      <td></td>\n      <td></td>\n      <td>MagneticFieldStrength</td>\n      <td></td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>True</td>\n      <td>False</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>/kaggle/input/hippocampal-sparing-dataset/Hipp...</td>\n      <td>None</td>\n      <td>MR</td>\n      <td>True</td>\n      <td>PatientName;PatientID</td>\n      <td>False</td>\n      <td></td>\n      <td></td>\n      <td>MagneticFieldStrength</td>\n      <td></td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>True</td>\n      <td>False</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>/kaggle/input/hippocampal-sparing-dataset/Hipp...</td>\n      <td>None</td>\n      <td>MR</td>\n      <td>True</td>\n      <td>PatientName;PatientID</td>\n      <td>False</td>\n      <td></td>\n      <td></td>\n      <td>MagneticFieldStrength</td>\n      <td></td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>True</td>\n      <td>False</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}],"execution_count":23},{"cell_type":"markdown","source":"## 11. Save Report as CSV (Optional)\n\nYou can download this CSV from Kaggle and feed it into your QA workflow, Jira, or whatever defect tracking system you use.\n","metadata":{}},{"cell_type":"code","source":"# ===========================\n# 11. Save CSV\n# ===========================\n\noutput_path = \"/kaggle/working/dicom_qc_report.csv\"\ndf.to_csv(output_path, index=False)\nprint(\"Saved report to:\", output_path)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-11T17:50:04.375609Z","iopub.execute_input":"2025-12-11T17:50:04.375893Z","iopub.status.idle":"2025-12-11T17:50:04.401153Z","shell.execute_reply.started":"2025-12-11T17:50:04.375863Z","shell.execute_reply":"2025-12-11T17:50:04.400173Z"}},"outputs":[{"name":"stdout","text":"Saved report to: /kaggle/working/dicom_qc_report.csv\n","output_type":"stream"}],"execution_count":24},{"cell_type":"markdown","source":"## 12. Next Steps / Hardening Ideas\n\nThis script is intentionally **basic**. To make it more production-grade:\n\n- Tie anonymization rules directly to your **DICOM profile** (CT vs MR vs RTSTRUCT etc.).\n- Add **UID pattern checks** (e.g., all UIDs re-rooted under a specific anonymized root).\n- Integrate with a **formal DICOM validator** for deeper attribute model checks.\n- For clinical datasets, expand PHI checks to free-text fields (e.g., `StudyDescription`, `SeriesDescription`) via:\n  - regex for MRNs,\n  - dictionaries for hospital names, city names, etc.\n- Convert this into a **Python package** and call it from:\n  - CI pipelines,\n  - preprocessing scripts for ML,\n  - or your regulatory QA toolchain.\n\nFor now, this notebook gives you a **fast, dataset-level smoke test** for anonymization and header sanity.\n","metadata":{}}]}
